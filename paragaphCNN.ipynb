{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordEmbeddingDimension = 50\n",
    "vocabularySize=100\n",
    "labels=10\n",
    "filterSizes_paragraph = [3]\n",
    "filterSizes_allPara=3\n",
    "paragraphLength=10\n",
    "num_filters_parargaph=15\n",
    "num_filters_allPara=20\n",
    "maxParagraph = 5\n",
    "\n",
    "filterShapeOfAllPara =[filterSizes_allPara,3,1,num_filters_allPara]\n",
    "fullyConnectedLayerInput = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordEmbedding = tf.Variable(tf.random_uniform([vocabularySize, wordEmbeddingDimension], -1.0, 1.0))\n",
    "\n",
    "# paragraphWords = tf.placeholder(tf.int32,[paragraphLength])\n",
    "\n",
    "paragraphList = []\n",
    "for i in range(maxParagraph):\n",
    "    paragraphList.append(tf.placeholder(tf.int32,[paragraphLength]))\n",
    "\n",
    "target = tf.placeholder(tf.float32,[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paragraph=[[1,2,3,4,5,6,7,8,9,10],[1,2,3,4,5,6,7,8,9,10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getParagraphEmbedding(paragraphWords):\n",
    "    paraEmbedding=tf.nn.embedding_lookup(wordEmbedding,paragraphWords)\n",
    "    \n",
    "    return tf.expand_dims(tf.expand_dims(paraEmbedding, -1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphVector = getParagraphEmbedding(paragraphList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims_11:0' shape=(1, 10, 50, 1) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convLayeronParagraph(paragraphVector,filterSizes,num_input_channels,num_filters):\n",
    "    \n",
    "    pooled_outputs=[]\n",
    "    for filter_size in filterSizes:\n",
    "        shape = [filter_size,wordEmbeddingDimension,1,num_filters]\n",
    "        \n",
    "        weights = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "        bias= tf.Variable(tf.constant(0.1, shape=[num_filters]))\n",
    "        conv = tf.nn.conv2d(\n",
    "                    paragraphVector,\n",
    "                    weights,\n",
    "                    strides=[1, 1, wordEmbeddingDimension, 1],\n",
    "                    padding=\"SAME\",\n",
    "                    name=\"conv\")\n",
    "        \n",
    "        h = tf.nn.relu(tf.nn.bias_add(conv, bias), name=\"relu\")\n",
    "        pool_length=5\n",
    "        pooled = tf.nn.max_pool(\n",
    "                    h,\n",
    "                    ksize=[1, pool_length, 1, 1],\n",
    "                    strides=[1, pool_length, 1, 1],\n",
    "                    padding='SAME',\n",
    "                    name=\"pool\")\n",
    "        pooled_outputs.append(pooled)\n",
    "    return tf.reshape(tf.concat(pooled_outputs,axis=0),[1,-1])\n",
    "#     filter_size = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphCNNOutput = convLayeronParagraph (paragraphVector,filterSizes,1,num_filters_parargaph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_21:0' shape=(1, 30) dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphCNNOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convLayerCombineParagraph(paragraphVectorList,filterSizes_paragraph,filterShapeOfAllPara,num_filters_parargaph,num_filters_allPara):\n",
    "    \n",
    "    paragraphCNNEmbedding=[]\n",
    "    \n",
    "    for paragraph in paragraphVectorList:\n",
    "        paragraphVector = getParagraphEmbedding(paragraph)\n",
    "        cnnEmbedding = convLayeronParagraph(paragraphVector,filterSizes_paragraph,1,num_filters_parargaph)\n",
    "        paragraphCNNEmbedding.append(cnnEmbedding)\n",
    "    \n",
    "    allParagraph=tf.expand_dims(tf.expand_dims(tf.concat(paragraphCNNEmbedding,axis=0),-1),0)\n",
    "    \n",
    "    shape = filterShapeOfAllPara\n",
    "    \n",
    "    weights= tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    bias= tf.Variable(tf.constant(0.1, shape=[num_filters_allPara]))\n",
    "    \n",
    "    conv = tf.nn.conv2d(\n",
    "                    allParagraph,\n",
    "                    weights,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"SAME\",\n",
    "                    name=\"conv\")\n",
    "    h = tf.nn.relu(tf.nn.bias_add(conv, bias), name=\"relu\")\n",
    "    return tf.reshape(allParagraph,[1,-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_94:0\", shape=(1, 150), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "convOutput=convLayerCombineParagraph(paragraphList,filterSizes_paragraph,filterShapeOfAllPara,num_filters_parargaph,num_filters_allPara)\n",
    "print(convOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullyConnectedLayer(convOutput,labels):\n",
    "    shape = [fullyConnectedLayerInput,labels]\n",
    "    weights =tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=[labels]))\n",
    "    layer = tf.nn.sigmoid(tf.matmul(convOutput, weights) + bias)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=fullyConnectedLayer(convOutput,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(((target*tf.log(prediction + 1e-9)) + ((1-target) * tf.log(1 - prediction + 1e-9)) )  , name='xentropy' ) \n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
